{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\aksha\\anaconda3\\envs\\sihenv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "genai.configure(api_key=\"AIzaSyBGj1rmJqOmahwj_2b5upsfln2qg5T_SOA\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pdf(file_path):\n",
    "    loader = PyPDFLoader(file_path)\n",
    "    documents = loader.load()\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_split(extracted_data):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=20)\n",
    "    text_chunks = text_splitter.split_documents(extracted_data)\n",
    "    return text_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_data = load_pdf(\"C:\\\\Users\\\\aksha\\\\OneDrive\\\\Desktop\\\\sih_cb\\\\Q and A.pdf\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_chunks = text_split(extracted_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_context_from_knowledge_base(query, text_chunks):\n",
    "    context = \"\\n\".join([t.page_content for t in text_chunks[:3]])  \n",
    "    return context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_gemini(query, context):\n",
    "    # Generative model setup\n",
    "    model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
    "\n",
    "    # Create the prompt by combining context and question in a conversational format\n",
    "    prompt = f\"\"\"\n",
    "    Context: {context}\n",
    "    \n",
    "    Question: {query}\n",
    "    \n",
    "    Instructions:\n",
    "    1. Provide a clear and concise response based on the context and your existing knowledge.\n",
    "    2. Don't quote the knowledge base directly; instead, summarize the relevant information in your own words.\n",
    "    3. If the question is not fully covered by the knowledge base, acknowledge the gap and inform the user that your training is based on a specific dataset that may not include all information.\n",
    "    4. Aim for answers that are informative, helpful, and relevant to the question asked.\n",
    "    5. Do not start answers with Hi there! or Based on the provided information or The provided text focuses on\n",
    "\n",
    "Please respond in a friendly and informative tone.\n",
    "    \"\"\"\n",
    "\n",
    "    # Generate the response from Gemini\n",
    "    response = model.generate_content(prompt)\n",
    "    return response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chatbot():\n",
    "    print(\"\\nHello! Welcome to the chatbot. Ask me any question, and I'll do my best to help you!\")\n",
    "    \n",
    "    while True:\n",
    "        try:\n",
    "            user_input = input(\"\\nInput your question (type 'exit' to stop): \")\n",
    "            \n",
    "            if user_input.lower() == 'exit':\n",
    "                print(\"\\nThank you for using the chatbot! Have a great day!\")\n",
    "                break\n",
    "\n",
    "            # Create context from the knowledge base (use some relevant documents)\n",
    "            context = create_context_from_knowledge_base(user_input, text_chunks)\n",
    "\n",
    "            # Ask Gemini model using the context and user query\n",
    "            response = ask_gemini(user_input, context)\n",
    "\n",
    "            print(f\"\\nUser Question: {user_input}\")\n",
    "            print(f\"Bot Response: {response}\\n\")\n",
    "        \n",
    "        except KeyboardInterrupt:\n",
    "            print(\"\\nThank you for using the chatbot! Have a great day!\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Hello! Welcome to the chatbot. Ask me any question, and I'll do my best to help you!\n",
      "\n",
      "User Question:  how does navshiksha tackels bandwth in rural areas\n",
      "Bot Response: The provided text describes features of an online learning platform, but it doesn't contain any information about how Navshiksha addresses bandwidth issues in rural areas.  My knowledge is limited to the information given, so I can't answer your question about Navshiksha's bandwidth solutions.\n",
      "\n",
      "\n",
      "\n",
      "Thank you for using the chatbot! Have a great day!\n"
     ]
    }
   ],
   "source": [
    "chatbot()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sihenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
